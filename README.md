# AI YouTube Explorer: Computer Vision-Powered Handwriting & Voice-Driven Q&A

## ğŸ“Œ Overview
**AI YouTube Explorer** is a cutting-edge project that utilizes **Computer Vision, Speech Recognition, and AI-powered Q&A** to interactively search YouTube, transcribe videos, and answer user queries. The system allows users to perform YouTube searches via **handwriting recognition** or **voice commands**, retrieve video transcriptions, and interact with an AI chatbot for insights.

## ğŸš€ Features
- **Handwriting Recognition** âœï¸: Use your finger or stylus to write a query, which gets converted into text.
- **Voice Commands** ğŸ¤: Speak your query, and the system retrieves the answer from the transcribed video via pinecone 
- **YouTube API Integration** ğŸ“º: Searches and filters YouTube videos based on duration and relevance.
- **Gesture-Based Video Selection** âœ‹: Uses hand-tracking to choose and play a video.
- **Video Transcription** ğŸ“: Retrieves subtitles from selected YouTube videos.
- **AI-Powered Q&A** ğŸ¤–: Uses a **Retrieval-Augmented Generation (RAG)** pipeline to answer questions based on the video content.

## ğŸ—ï¸ Tech Stack
- **Computer Vision**: OpenCV, MediaPipe (for hand tracking & gesture recognition)
- **Speech-to-Text**: Deepgram API (for transcribing voice input)
- **Natural Language Processing**: OpenAI API (for query refinement & Q&A)
- **Vector Database**: Pinecone (to store & retrieve transcribed video data)
- **Frontend & UI**: Gradio (for interactive AI-driven Q&A)
- **Backend**: Python, Google YouTube API (for video search & metadata retrieval)

## ğŸ› ï¸ Installation
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/AI-YouTube-Explorer.git
cd AI-YouTube-Explorer
```

### 2ï¸âƒ£ Set Up a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # On MacOS/Linux
venv\Scripts\activate  # On Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure API Keys
Create a `.env` file in the root directory and add:
```plaintext
YOUTUBE_API_KEY=your_youtube_api_key
DEEPGRAM_API_KEY=your_deepgram_api_key
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX=your_pinecone_index_name
```

## â–¶ï¸ Usage
Run the main controller script to launch the pipeline:
```bash
python main_controller.py
```
### Workflow:
1. **Handwriting or Voice Input** â†’ User writes or speaks a YouTube query.
2. **Query Refinement** â†’ AI refines the search query.
3. **YouTube Search** â†’ Retrieves top 3 relevant videos.
4. **Gesture-Based Selection** â†’ User selects a video using hand gestures.
5. **Video Transcription & Storage** â†’ Retrieves subtitles and stores them in Pinecone.
6. **AI-Powered Q&A** â†’ Users can ask questions based on the video content.

## ğŸ“Œ File Structure
```
AI-YouTube-Explorer/
â”‚â”€â”€ app.py                      # Handwriting recognition
â”‚â”€â”€ deepgram_speech_to_text.py   # Voice transcription
â”‚â”€â”€ guardrails_filter.py         # Query refinement
â”‚â”€â”€ youtube_filtered_search.py   # YouTube search
â”‚â”€â”€ youtube_video_selector.py    # Gesture-based selection
â”‚â”€â”€ dynamic_youtube_transcriber.py # Video transcription
â”‚â”€â”€ main_controller.py           # Runs all components
â”‚â”€â”€ .env                         # API keys (ignored in Git)
â”‚â”€â”€ .gitignore                   # Files to exclude from Git
â”‚â”€â”€ requirements.txt             # Dependencies
â”‚â”€â”€ README.md                    # Project documentation
```


